{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coral-scottish",
   "metadata": {},
   "source": [
    "## Web Scrapping Job from Upwork\n",
    "\n",
    "### Objective:\n",
    "\n",
    "- Collect following data from the website: https://industryexpert.net/expert-directory/\n",
    "    - \"Name (First Last)\", \"Title\", \"Company Name\", \"Categories\", \"Website\", \"E-Mail\"\n",
    "- Export the data as an excel, including one worksheet with all categories as well as each category per worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subdomains and category names of each category\n",
    "\n",
    "url = f\"https://industryexpert.net/expert-directory/\"\n",
    "req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "\n",
    "cat_urls = soup.find_all(\"ul\", \"cn-cat-tree dropdown-menu\")\n",
    "subdomain_list = []\n",
    "category_list = []\n",
    "\n",
    "for urls in cat_urls:\n",
    "    for url in urls.find_all(\"a\"):\n",
    "        subdomain = url.get(\"href\").rsplit(\"/\", 2)[-2]\n",
    "        cat = url.get(\"title\")\n",
    "        category_list.append(cat)\n",
    "        subdomain_list.append(subdomain)\n",
    "\n",
    "cat_subdom_dict = dict(zip(category_list, subdomain_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of lists of experts information\n",
    "\n",
    "def create_experts_info_list(url):\n",
    "    req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "    soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "    experts_info = []\n",
    "    experts = soup.find_all(\"div\", \"cn-entry expert\")\n",
    "    \n",
    "    for expert in experts:\n",
    "\n",
    "        # Name\n",
    "        fname = expert.find(\"span\", \"given-name\")\n",
    "        mname = expert.find(\"span\", \"additional-name\")\n",
    "        lname = expert.find(\"span\", \"family-name\")\n",
    "        if mname:\n",
    "            name_text = f\"{fname.text} {mname.text} {lname.text}\"\n",
    "        else:\n",
    "            name_text = f\"{fname.text} {lname.text}\"\n",
    "\n",
    "        # Title\n",
    "        title = expert.find(\"span\", \"title notranslate\")\n",
    "        title_text = title.text if title else \"n/a\"\n",
    "\n",
    "        # Company name\n",
    "        org = expert.find(\"span\", \"org\")\n",
    "        org_text = org.text if org else \"n/a\"\n",
    "\n",
    "        # Categories\n",
    "        cats = expert.find_all(\"span\", \"cn-category-name\")\n",
    "        if len(cats) == 1: # only 1 \n",
    "            cats_text = cats[0].text\n",
    "\n",
    "        else:\n",
    "            cats_text = [cat.text.replace(\", \", \"\") for cat in cats]\n",
    "\n",
    "        # Website\n",
    "        websites = expert.find_all(\"a\", \"url\")\n",
    "        if websites:\n",
    "    \n",
    "            for website in websites:\n",
    "                website_link = website.get(\"href\") \n",
    "        else:\n",
    "            website_link = \"n/a\"\n",
    "\n",
    "        # Email\n",
    "        emails = expert.find_all(\"span\", \"email-address\")\n",
    "        if len(emails) == 0 :\n",
    "            emails_text = \"n/a\"\n",
    "        elif len(emails) == 1: # only 1 \n",
    "            emails_text = emails[0].text\n",
    "        else:\n",
    "            emails_text = \", \".join([emails[0].text for email in emails])\n",
    "\n",
    "        expert_info = [name_text, title_text, org_text, cats_text, website_link, emails_text]\n",
    "        experts_info.append(expert_info)\n",
    "\n",
    "    print(\"----\")\n",
    "        \n",
    "    return experts_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with the list of lists experts info\n",
    "\n",
    "def create_df(subdomain, cat=\"overall\"):\n",
    "    keys = [\"Name (First Last)\", \"Title\", \"Company Name\", \"Categories\", \"Website\", \"E-Mail\"]\n",
    "    experts_info = []\n",
    "    base_url = \"https://industryexpert.net/expert-directory/\"\n",
    "    \n",
    "    if cat == \"overall\":\n",
    "        print(f\"Creating {cat} dataframe\")\n",
    "\n",
    "        for i in range(1, 24):\n",
    "\n",
    "            print(f\"----PAGE {i}-----\")\n",
    "            print(\"\\n\")\n",
    "            url = os.path.join(base_url, f\"?cn-pg={i}\")\n",
    "            print(url)\n",
    "            new_list = create_experts_info_list(url)\n",
    "            print(new_list)\n",
    "            experts_info.extend(new_list)\n",
    "\n",
    "    else:\n",
    "        print(f\"Creating {cat} dataframe\")\n",
    "        url = os.path.join(base_url, \"cat\", subdomain)\n",
    "        print(url)\n",
    "        \n",
    "        experts_info = create_experts_info_list(url)\n",
    "\n",
    "    pprint(experts_info)\n",
    "    print(f\"Length: {len(experts_info)}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.DataFrame(np.array(experts_info), columns=keys)\n",
    "    except ValueError:\n",
    "        print(\"-- No data in this category. --\")\n",
    "        df = None\n",
    "    print(\"--- Data Frame created successfully ---\")    \n",
    "    print(\"--------------------------\")    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe dictionary:\n",
    "# key = category and value = dataframe\n",
    "\n",
    "df_dict = dict()\n",
    "for c, subdom in cat_subdom_dict.items():\n",
    "    df_c = create_df(subdom, cat=c)\n",
    "    df_dict[c] = df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with all values\n",
    "df_dict['OVERALL'] = create_df(subdomain, cat=\"overall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall = df_dict['OVERALL'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to excel\n",
    "with pd.ExcelWriter('experts.xlsx') as writer:\n",
    "    df_overall.to_excel(writer, sheet_name='OVERALL')\n",
    "    for cat, df in df_dict.items():\n",
    "        if len(cat) > 31:\n",
    "            cat = \"\".join(cat.split(\" \")[:2])\n",
    "        try:\n",
    "            df.to_excel(writer, sheet_name=re.sub(r'[\\[\\]\\:\\*\\?\\/\\\\]', '', cat))\n",
    "        except AttributeError:\n",
    "            keys = [\"Name (First Last)\", \"Title\", \"Company Name\", \"Categories\", \"Website\", \"E-Mail\"]\n",
    "            df = pd.DataFrame(columns=keys)\n",
    "            df.to_excel(writer, sheet_name=re.sub(r'[\\[\\]\\:\\*\\?\\/\\\\]', '', cat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
