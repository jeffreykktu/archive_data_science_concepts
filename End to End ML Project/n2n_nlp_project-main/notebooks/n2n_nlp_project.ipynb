{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### End 2 End NLP Project (Walk Through)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "+ Emotion Detection In Text\n",
    "+ Text Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# Load EDA packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "# Load Data Viz Packages\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "# Load Text Cleaning Packages\n",
    "import neattext.functions as nfx"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "# Load ML packages\n",
    "# Estimators\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Transformers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"../data/emotion_dataset_2.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
       "      <td>Sage Act upgrade list tommorow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
       "      <td>WAY HOMEGIRL BABY FUNERAL MAN HATE FUNERALS SH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
       "      <td>eye  true hazel eyeand brilliant  Regular feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>joy</td>\n",
       "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
       "      <td>ugh babe hugggzzz u  babe naamazed nga ako e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Emotion                                               Text  \\\n",
       "0           0  neutral                                             Why ?    \n",
       "1           1      joy    Sage Act upgrade on my to do list for tommorow.   \n",
       "2           2  sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...   \n",
       "3           3      joy   Such an eye ! The true hazel eye-and so brill...   \n",
       "4           4      joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b...   \n",
       "\n",
       "                                          Clean_Text  \n",
       "0                                                NaN  \n",
       "1                     Sage Act upgrade list tommorow  \n",
       "2  WAY HOMEGIRL BABY FUNERAL MAN HATE FUNERALS SH...  \n",
       "3  eye  true hazel eyeand brilliant  Regular feat...  \n",
       "4    ugh babe hugggzzz u  babe naamazed nga ako e...  "
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "# Value Counts\n",
    "df['Emotion'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "joy         11045\n",
       "sadness      6722\n",
       "fear         5410\n",
       "anger        4297\n",
       "surprise     4062\n",
       "neutral      2254\n",
       "disgust       856\n",
       "shame         146\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "# Plot\n",
    "sns.countplot(x='Emotion', data=df)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Emotion', ylabel='count'>"
      ]
     },
     "metadata": {},
     "execution_count": 89
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "# Data Cleaning\n",
    "dir(nfx)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['BTC_ADDRESS_REGEX',\n",
       " 'CURRENCY_REGEX',\n",
       " 'CURRENCY_SYMB_REGEX',\n",
       " 'Counter',\n",
       " 'DATE_REGEX',\n",
       " 'EMAIL_REGEX',\n",
       " 'EMOJI_REGEX',\n",
       " 'HASTAG_REGEX',\n",
       " 'MASTERCard_REGEX',\n",
       " 'MD5_SHA_REGEX',\n",
       " 'MOST_COMMON_PUNCT_REGEX',\n",
       " 'NUMBERS_REGEX',\n",
       " 'PHONE_REGEX',\n",
       " 'PoBOX_REGEX',\n",
       " 'SPECIAL_CHARACTERS_REGEX',\n",
       " 'STOPWORDS',\n",
       " 'STOPWORDS_de',\n",
       " 'STOPWORDS_en',\n",
       " 'STOPWORDS_es',\n",
       " 'STOPWORDS_fr',\n",
       " 'STOPWORDS_ru',\n",
       " 'STOPWORDS_yo',\n",
       " 'STREET_ADDRESS_REGEX',\n",
       " 'TextFrame',\n",
       " 'URL_PATTERN',\n",
       " 'USER_HANDLES_REGEX',\n",
       " 'VISACard_REGEX',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__generate_text',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__numbers_dict',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_lex_richness_herdan',\n",
       " '_lex_richness_maas_ttr',\n",
       " 'clean_text',\n",
       " 'defaultdict',\n",
       " 'digit2words',\n",
       " 'extract_btc_address',\n",
       " 'extract_currencies',\n",
       " 'extract_currency_symbols',\n",
       " 'extract_dates',\n",
       " 'extract_emails',\n",
       " 'extract_emojis',\n",
       " 'extract_hashtags',\n",
       " 'extract_html_tags',\n",
       " 'extract_mastercard_addr',\n",
       " 'extract_md5sha',\n",
       " 'extract_numbers',\n",
       " 'extract_pattern',\n",
       " 'extract_phone_numbers',\n",
       " 'extract_postoffice_box',\n",
       " 'extract_shortwords',\n",
       " 'extract_special_characters',\n",
       " 'extract_stopwords',\n",
       " 'extract_street_address',\n",
       " 'extract_urls',\n",
       " 'extract_userhandles',\n",
       " 'extract_visacard_addr',\n",
       " 'fix_contractions',\n",
       " 'generate_sentence',\n",
       " 'hamming_distance',\n",
       " 'inverse_df',\n",
       " 'lexical_richness',\n",
       " 'markov_chain',\n",
       " 'math',\n",
       " 'nlargest',\n",
       " 'normalize',\n",
       " 'num2words',\n",
       " 'random',\n",
       " 're',\n",
       " 'read_txt',\n",
       " 'remove_bad_quotes',\n",
       " 'remove_btc_address',\n",
       " 'remove_currencies',\n",
       " 'remove_currency_symbols',\n",
       " 'remove_custom_pattern',\n",
       " 'remove_custom_words',\n",
       " 'remove_dates',\n",
       " 'remove_emails',\n",
       " 'remove_emojis',\n",
       " 'remove_hashtags',\n",
       " 'remove_html_tags',\n",
       " 'remove_mastercard_addr',\n",
       " 'remove_md5sha',\n",
       " 'remove_multiple_spaces',\n",
       " 'remove_non_ascii',\n",
       " 'remove_numbers',\n",
       " 'remove_phone_numbers',\n",
       " 'remove_postoffice_box',\n",
       " 'remove_puncts',\n",
       " 'remove_punctuations',\n",
       " 'remove_shortwords',\n",
       " 'remove_special_characters',\n",
       " 'remove_stopwords',\n",
       " 'remove_street_address',\n",
       " 'remove_urls',\n",
       " 'remove_userhandles',\n",
       " 'remove_visacard_addr',\n",
       " 'replace_bad_quotes',\n",
       " 'replace_currencies',\n",
       " 'replace_currency_symbols',\n",
       " 'replace_dates',\n",
       " 'replace_emails',\n",
       " 'replace_emojis',\n",
       " 'replace_numbers',\n",
       " 'replace_phone_numbers',\n",
       " 'replace_special_characters',\n",
       " 'replace_term',\n",
       " 'replace_urls',\n",
       " 'string',\n",
       " 'term_freq',\n",
       " 'to_txt',\n",
       " 'word_freq',\n",
       " 'word_length_freq']"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# User handles\n",
    "df['Clean_Text'] = df['Text'].apply(nfx.remove_userhandles)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "# Stopwords\n",
    "df['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_shortwords)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
       "      <td>Sage upgrade list tommorow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
       "      <td>HOMEGIRL BABY FUNERAL HATE FUNERALS THIS REALL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
       "      <td>Such true hazel brilliant Regular features ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>joy</td>\n",
       "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
       "      <td>babe hugggzzz babe naamazed babe despite nega ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34787</th>\n",
       "      <td>34787</td>\n",
       "      <td>surprise</td>\n",
       "      <td>@MichelGW have you gift! Hope you like it! It'...</td>\n",
       "      <td>have gift Hope like hand made wear keep warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34788</th>\n",
       "      <td>34788</td>\n",
       "      <td>joy</td>\n",
       "      <td>The world didnt give it to me..so the world MO...</td>\n",
       "      <td>world didnt give world MOST DEFINITELY take away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>34789</td>\n",
       "      <td>anger</td>\n",
       "      <td>A man robbed me today .</td>\n",
       "      <td>robbed today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34790</th>\n",
       "      <td>34790</td>\n",
       "      <td>fear</td>\n",
       "      <td>Youu call it JEALOUSY, I call it of #Losing YO...</td>\n",
       "      <td>Youu call JEALOUSY call Losing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34791</th>\n",
       "      <td>34791</td>\n",
       "      <td>sadness</td>\n",
       "      <td>I think about you baby, and I dream about you ...</td>\n",
       "      <td>think about baby dream about time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34792 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   Emotion  \\\n",
       "0               0   neutral   \n",
       "1               1       joy   \n",
       "2               2   sadness   \n",
       "3               3       joy   \n",
       "4               4       joy   \n",
       "...           ...       ...   \n",
       "34787       34787  surprise   \n",
       "34788       34788       joy   \n",
       "34789       34789     anger   \n",
       "34790       34790      fear   \n",
       "34791       34791   sadness   \n",
       "\n",
       "                                                    Text  \\\n",
       "0                                                 Why ?    \n",
       "1        Sage Act upgrade on my to do list for tommorow.   \n",
       "2      ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...   \n",
       "3       Such an eye ! The true hazel eye-and so brill...   \n",
       "4      @Iluvmiasantos ugh babe.. hugggzzz for u .!  b...   \n",
       "...                                                  ...   \n",
       "34787  @MichelGW have you gift! Hope you like it! It'...   \n",
       "34788  The world didnt give it to me..so the world MO...   \n",
       "34789                           A man robbed me today .    \n",
       "34790  Youu call it JEALOUSY, I call it of #Losing YO...   \n",
       "34791  I think about you baby, and I dream about you ...   \n",
       "\n",
       "                                              Clean_Text  \n",
       "0                                                         \n",
       "1                             Sage upgrade list tommorow  \n",
       "2      HOMEGIRL BABY FUNERAL HATE FUNERALS THIS REALL...  \n",
       "3      Such true hazel brilliant Regular features ope...  \n",
       "4      babe hugggzzz babe naamazed babe despite nega ...  \n",
       "...                                                  ...  \n",
       "34787       have gift Hope like hand made wear keep warm  \n",
       "34788   world didnt give world MOST DEFINITELY take away  \n",
       "34789                                       robbed today  \n",
       "34790                     Youu call JEALOUSY call Losing  \n",
       "34791                  think about baby dream about time  \n",
       "\n",
       "[34792 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "# Features & Labels\n",
    "X = df['Clean_Text']\n",
    "y = df['Emotion']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "# Split Data into training and others\n",
    "X_train, X_else, y_train, y_else = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# Split Data from else into validation set and test set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_else, y_else, test_size=0.5, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compare 3 Algorithms' Performance:\n",
    "1. Logistic Regression\n",
    "2. SVM\n",
    "3. Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# Ignore warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "# Print the results of cross val\n",
    "def print_results(results):\n",
    "    print(f\"Best Parameters: {results.best_params_}\\n\")\n",
    "    \n",
    "    means = results.cv_results_[\"mean_test_score\"]\n",
    "    stds = results.cv_results_[\"std_test_score\"]\n",
    "    params = results.cv_results_[\"params\"]\n",
    "    for mean, std, param in zip(means, stds, params):\n",
    "        print(f\"{mean:.3f} (+/-{std*2:.3f}) for {param}\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# Import LR packages\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# 5 Fold Cross Validation\n",
    "lr = LogisticRegression()\n",
    "params = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "cv_lr = GridSearchCV(lr, params, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# Build Pipeline for Cross Val\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe_cv_lr = Pipeline(steps=[(\"cnt_vec\", CountVectorizer()), ('cv_lr', cv_lr)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "# Train and Fit data\n",
    "pipe_cv_lr.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cnt_vec', CountVectorizer()),\n",
       "                ('cv_lr',\n",
       "                 GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "                              param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                                                1000]}))])"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "# Check the paramaters \n",
    "print_results(cv_lr)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Parameters: {'C': 1}\n",
      "\n",
      "0.331 (+/-0.002) for {'C': 0.001}\n",
      "0.440 (+/-0.005) for {'C': 0.01}\n",
      "0.565 (+/-0.017) for {'C': 0.1}\n",
      "0.605 (+/-0.011) for {'C': 1}\n",
      "0.585 (+/-0.007) for {'C': 10}\n",
      "0.574 (+/-0.007) for {'C': 100}\n",
      "0.564 (+/-0.006) for {'C': 1000}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "# Print the best estimator\n",
    "cv_lr.best_estimator_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=1)"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "pipe_lr_best = Pipeline(steps=[(\"cnt_vec\", CountVectorizer()), (\"best_lr\", cv_lr.best_estimator_)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "from sklearn.svm import SVC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# 5 Fold Cross Validation\n",
    "svc = SVC()\n",
    "params = {\n",
    "    \"kernel\": [\"linear\"],\n",
    "    \"C\": [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "cv_svc = GridSearchCV(svc, params, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "pipe_cv_svc = Pipeline(steps=[(\"cnt_vec\", CountVectorizer()), (\"cv_svc\", cv_svc)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# Fit data\n",
    "pipe_cv_svc.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cnt_vec', CountVectorizer()),\n",
       "                ('cv_svc',\n",
       "                 GridSearchCV(cv=5, estimator=SVC(),\n",
       "                              param_grid={'C': [0.1, 1, 10],\n",
       "                                          'kernel': ['linear']}))])"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "# Print params\n",
    "print_results(cv_svc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Parameters: {'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "0.562 (+/-0.015) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.579 (+/-0.009) for {'C': 1, 'kernel': 'linear'}\n",
      "0.543 (+/-0.008) for {'C': 10, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "# print the best estimator\n",
    "cv_svc.best_estimator_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "# Output the best param pipeline\n",
    "pipe_svc_best = Pipeline(steps=[(\"cnt_vec\", CountVectorizer()), (\"best_svc\", cv_svc.best_estimator_)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# Import random forest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# 5 Fold Cross Validation\n",
    "rf = RandomForestClassifier()\n",
    "params = {\n",
    "    \"n_estimators\": [5, 50, 250],\n",
    "    \"max_depth\": [2, 4, 6, 8, 16]\n",
    "}\n",
    "cv_rf = GridSearchCV(rf, params, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "pipe_cv_rf = Pipeline(steps=[(\"cnt_vec\", CountVectorizer()), (\"cv_rf\", cv_rf)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "# Train the data\n",
    "pipe_cv_rf.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cnt_vec', CountVectorizer()),\n",
       "                ('cv_rf',\n",
       "                 GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                              param_grid={'max_depth': [2, 4, 6, 8, 16],\n",
       "                                          'n_estimators': [5, 50, 250]}))])"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# Show the params\n",
    "print_results(cv_rf)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Parameters: {'max_depth': 16, 'n_estimators': 5}\n",
      "\n",
      "0.326 (+/-0.007) for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.318 (+/-0.000) for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.318 (+/-0.000) for {'max_depth': 2, 'n_estimators': 250}\n",
      "0.342 (+/-0.008) for {'max_depth': 4, 'n_estimators': 5}\n",
      "0.318 (+/-0.000) for {'max_depth': 4, 'n_estimators': 50}\n",
      "0.318 (+/-0.000) for {'max_depth': 4, 'n_estimators': 250}\n",
      "0.342 (+/-0.022) for {'max_depth': 6, 'n_estimators': 5}\n",
      "0.322 (+/-0.008) for {'max_depth': 6, 'n_estimators': 50}\n",
      "0.318 (+/-0.003) for {'max_depth': 6, 'n_estimators': 250}\n",
      "0.345 (+/-0.018) for {'max_depth': 8, 'n_estimators': 5}\n",
      "0.329 (+/-0.003) for {'max_depth': 8, 'n_estimators': 50}\n",
      "0.328 (+/-0.002) for {'max_depth': 8, 'n_estimators': 250}\n",
      "0.381 (+/-0.026) for {'max_depth': 16, 'n_estimators': 5}\n",
      "0.346 (+/-0.006) for {'max_depth': 16, 'n_estimators': 50}\n",
      "0.339 (+/-0.002) for {'max_depth': 16, 'n_estimators': 250}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# print the best estimator\n",
    "cv_rf.best_estimator_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=16, n_estimators=5)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "# Output the best param pipeline\n",
    "pipe_rf_best = Pipeline(steps=[(\"cnt_vec\", CountVectorizer()), (\"cv_rf\", cv_rf.best_estimator_)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using Validation set to choose the best algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "# LR\n",
    "pipe_lr_best.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/jeffreykktu_updated/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cnt_vec', CountVectorizer()),\n",
       "                ('best_lr', LogisticRegression(C=1))])"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "# SVC\n",
    "pipe_svc_best.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cnt_vec', CountVectorizer()),\n",
       "                ('best_svc', SVC(C=1, kernel='linear'))])"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# RF\n",
    "pipe_rf_best.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cnt_vec', CountVectorizer()),\n",
       "                ('cv_rf',\n",
       "                 RandomForestClassifier(max_depth=16, n_estimators=5))])"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "# Compare the accuracy with validation set\n",
    "model_dict = {\"lr\": pipe_lr_best, \"svc\": pipe_svc_best, \"rf\": pipe_rf_best}\n",
    "for model in model_dict:\n",
    "    model_score = model_dict[model].score(X_val, y_val)\n",
    "    print(f\"{model}: {model_score}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lr: 0.6127610653381874\n",
      "svc: 0.5966660279747078\n",
      "rf: 0.39164590917800346\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Conclusion: Comparing the 3 algorithms, Logistic Regression performed the best"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "# Check accuracy with Test Set\n",
    "pipe_lr_best.score(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6106533818739222"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "# Make a Prediction\n",
    "ex1 = \"This song is exciting.\"\n",
    "ex2 = 'This song is pretty sad.'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "pipe_lr_best.predict([ex1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['joy'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "pipe_lr_best.predict([ex2])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['surprise'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "# Prediction Probability\n",
    "pipe_lr_best.predict_proba([ex1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.08895069, 0.01075775, 0.07631039, 0.4109189 , 0.12741872,\n",
       "        0.14847766, 0.00150815, 0.13565774]])"
      ]
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "pipe_lr_best.predict_proba([ex2])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.15608567, 0.02546254, 0.02979869, 0.17164699, 0.07857619,\n",
       "        0.21697633, 0.0014479 , 0.32000569]])"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "# To know the classes\n",
    "pipe_lr_best.classes_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'shame',\n",
       "       'surprise'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "# Save Model and Pipeline\n",
    "import joblib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "with open(\"20210722_emotion_classifier_pipe_lr_best.pkl\", \"wb\") as pipeline_file:\n",
    "    joblib.dump(pipe_lr_best, pipeline_file)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}